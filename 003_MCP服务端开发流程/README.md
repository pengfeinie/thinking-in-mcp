# MCPæœåŠ¡ç«¯å¼€å‘æµç¨‹

## 1. uvå·¥å…·å…¥é—¨ä½¿ç”¨æŒ‡å—

### 1.1 uvå…¥é—¨ä»‹ç»

MCPå¼€å‘è¦æ±‚å€ŸåŠ©uvè¿›è¡Œè™šæ‹Ÿç¯å¢ƒåˆ›å»ºå’Œä¾èµ–ç®¡ç†ã€‚uv æ˜¯ä¸€ä¸ªPython ä¾èµ–ç®¡ç†å·¥å…·ï¼Œç±»ä¼¼äº  pip å’Œ  conda ï¼Œä½†å®ƒæ›´å¿«ã€æ›´é«˜æ•ˆï¼Œå¹¶ä¸”å¯ä»¥æ›´å¥½åœ°ç®¡ç† Python è™šæ‹Ÿç¯å¢ƒå’Œä¾èµ–é¡¹ã€‚å®ƒçš„æ ¸å¿ƒç›®æ ‡æ˜¯ æ›¿ä»£  pip ã€ venv å’Œ  pip-tools  ï¼Œæä¾›æ›´å¥½çš„æ€§èƒ½å’Œæ›´ä½çš„ç®¡ç†å¼€é”€ã€‚ 

uv çš„ç‰¹ç‚¹ï¼š 

1. é€Ÿåº¦æ›´å¿«ï¼šç›¸æ¯”  pip ï¼Œuv é‡‡ç”¨ Rust ç¼–å†™ï¼Œæ€§èƒ½æ›´ä¼˜ã€‚
2.  æ”¯æŒ PEP 582ï¼šæ— éœ€  virtualenv ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨  
3. å…¼å®¹  pip  ï¼šæ”¯æŒ  __pypackages__ è¿›è¡Œç®¡ç†ã€‚ requirements.txt å’Œ  pyproject.toml ä¾èµ–ç®¡ç†ã€‚ 
4. æ›¿ä»£  venv  ï¼šæä¾›  uv venv è¿›è¡Œè™šæ‹Ÿç¯å¢ƒç®¡ç†ã€‚
5. è·¨å¹³å°ï¼šæ”¯æŒ Windowsã€macOS å’Œ Linux

### 1.2 uvå®‰è£…æµç¨‹  

æ–¹æ³• 1ï¼šä½¿ç”¨  pip å®‰è£…

```bash
pip install uv
```

æ–¹æ³• 2ï¼šä½¿ç”¨  curl ç›´æ¥å®‰è£…

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

è¿™ä¼šè‡ªåŠ¨ä¸‹è½½ uv å¹¶å®‰è£…åˆ°  /usr/local/bin

![](images/2025-03-21_133010.png)

## 2. å¤©æ°”æŸ¥è¯¢æœåŠ¡å™¨åˆ›å»ºæµç¨‹

### 2.1 åˆ›å»ºMCPæœåŠ¡ç«¯é¡¹ç›®

```bash
uv init my-mcp-server
cd my-mcp-server
```

![](images/2025-03-21_153036.png)

### 2.2 åˆ›å»ºMCPæœåŠ¡ç«¯è™šæ‹Ÿç¯å¢ƒ

```bash
# Create virtual environment
uv venv
# On Unix or MacOS:
source .venv/bin/activate
```

![](images/2025-03-21_153159.png)

ç„¶åå³å¯é€šè¿‡addæ–¹æ³•åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ç›¸å…³çš„åº“ã€‚

```bash
uv add mcp httpx
```

![](images/2025-03-21_153234.png)

### 2.3 ç¼–å†™å¤©æ°”æŸ¥è¯¢MCPæœåŠ¡ç«¯

```python
import json
import httpx
from typing import Any
from mcp.server.fastmcp import FastMCP

# åˆå§‹åŒ– MCP æœåŠ¡å™¨
mcp = FastMCP("WeatherServer")

# OpenWeather API é…ç½®
OPENWEATHER_API_BASE = "https://api.openweathermap.org/data/2.5/weather"
OPEN_WEATHER_API_KEY = "9e14e02f316c831ed171fc091d2fbf64"  # è¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ OpenWeather API Key
USER_AGENT = "weather-app/1.0"


async def fetch_weather(city: str) -> dict[str, Any] | None:
    """
    ä» OpenWeather API è·å–å¤©æ°”ä¿¡æ¯ã€‚
    :param city: åŸå¸‚åç§°ï¼ˆéœ€ä½¿ç”¨è‹±æ–‡ï¼Œå¦‚ Beijingï¼‰
    :return: å¤©æ°”æ•°æ®å­—å…¸ï¼›è‹¥å‡ºé”™è¿”å›åŒ…å« error ä¿¡æ¯çš„å­—å…¸
    """
    params = {
        "q": city,
        "appid": OPEN_WEATHER_API_KEY,
        "units": "metric",
        "lang": "zh_cn"
    }
    headers = {"User-Agent": USER_AGENT}
    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(OPENWEATHER_API_BASE, params=params, headers=headers, timeout=30.0)
            response.raise_for_status()
            return response.json()  # è¿”å›å­—å…¸ç±»å‹
        except httpx.HTTPStatusError as e:
            return {"error": f"HTTP é”™è¯¯: {e.response.status_code}"}
        except Exception as e:
            return {"error": f"è¯·æ±‚å¤±è´¥: {str(e)}"}


def format_weather(data: dict[str, Any] | str) -> str:
    """
    å°†å¤©æ°”æ•°æ®æ ¼å¼åŒ–ä¸ºæ˜“è¯»æ–‡æœ¬ã€‚
    :param data: å¤©æ°”æ•°æ®ï¼ˆå¯ä»¥æ˜¯å­—å…¸æˆ– JSON å­—ç¬¦ä¸²ï¼‰
    :return: æ ¼å¼åŒ–åçš„å¤©æ°”ä¿¡æ¯å­—ç¬¦ä¸²
    """
    # å¦‚æœä¼ å…¥çš„æ˜¯å­—ç¬¦ä¸²ï¼Œåˆ™å…ˆè½¬æ¢ä¸ºå­—å…¸
    if isinstance(data, str):
        try:
            data = json.loads(data)
        except Exception as e:
            return f"æ— æ³•è§£æå¤©æ°”æ•°æ®: {e}"
    # å¦‚æœæ•°æ®ä¸­åŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œç›´æ¥è¿”å›é”™è¯¯æç¤º
    if "error" in data:
        return f"âš  {data['error']}"
    # æå–æ•°æ®æ—¶åšå®¹é”™å¤„ç†
    city = data.get("name", "æœªçŸ¥")
    country = data.get("sys", {}).get("country", "æœªçŸ¥")
    temp = data.get("main", {}).get("temp", "N/A")
    humidity = data.get("main", {}).get("humidity", "N/A")
    wind_speed = data.get("wind", {}).get("speed", "N/A")
    # weather å¯èƒ½ä¸ºç©ºåˆ—è¡¨ï¼Œå› æ­¤ç”¨ [0] å‰å…ˆæä¾›é»˜è®¤å­—å…¸
    weather_list = data.get("weather", [{}])
    description = weather_list[0].get("description", "æœªçŸ¥")
    return (
        f"ğŸŒ {city}, {country}\n"
        f"ğŸŒ¡ æ¸©åº¦: {temp}Â°C\n"
        f"ğŸ’§ æ¹¿åº¦: {humidity}%\n"
        f"ğŸŒ¬ é£é€Ÿ: {wind_speed} m/s\n"
        f"â›… å¤©æ°”: {description}\n"
    )


@mcp.tool()
async def query_weather(city: str) -> str:
    """
    è¾“å…¥æŒ‡å®šåŸå¸‚çš„è‹±æ–‡åç§°ï¼Œè¿”å›ä»Šæ—¥å¤©æ°”æŸ¥è¯¢ç»“æœã€‚
    :param city: åŸå¸‚åç§°ï¼ˆéœ€ä½¿ç”¨è‹±æ–‡ï¼‰
    :return: æ ¼å¼åŒ–åçš„å¤©æ°”ä¿¡æ¯
    """
    data = await fetch_weather(city)
    return format_weather(data)


if __name__ == "__main__":
    # ä»¥æ ‡å‡† I/O æ–¹å¼è¿è¡Œ MCP æœåŠ¡å™¨
    mcp.run(transport='stdio')
```

### 2.4 ç¼–å†™å¤©æ°”æŸ¥è¯¢MCPå®¢æˆ·ç«¯

#### 2.5.1 æ–°å¢ä¾èµ–

```python
uv add mcp openai python-dotenv
```

#### 2.5.2 åˆ›å»º.envæ–‡ä»¶

```bash
touch .env

## åœ¨è¯¥æ–‡ä»¶å†…æ·»åŠ å¦‚ä¸‹é…ç½®
BASE_URL=https://api.deepseek.com
MODEL=deepseek-chat
OPENAI_API_KEY=<DeepSeek API Key>
```

#### 2.5.2 å®¢æˆ·ç«¯ä»£ç 

```python
import asyncio
import os
import json
from typing import Optional
from contextlib import AsyncExitStack
from openai import OpenAI
from dotenv import load_dotenv
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client


# åŠ è½½.envæ–‡ä»¶ï¼Œç¡®ä¿API Keyå—åˆ°ä¿æŠ¤
load_dotenv()


class MCPClient:
    def __init__(self):
        """åˆå§‹åŒ–MCPå®¢æˆ·ç«¯"""
        self.exit_stack = AsyncExitStack()
        self.openai_api_key = os.getenv("OPENAI_API_KEY")  # è¯»å–OpenAI API Key
        self.base_url = os.getenv("BASE_URL")  # è¯»å–BASE YRL
        self.model = os.getenv("MODEL")  # è¯»å–model

        if not self.openai_api_key:
            raise ValueError("âŒæœªæ‰¾åˆ°OpenAI API Keyï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")

        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url)
        # åˆ›å»ºOpenAI client
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()

    async def connect_to_server(self, server_script_path: str):
        """è¿æ¥åˆ°MCPæœåŠ¡å™¨å¹¶åˆ—å‡ºå¯ç”¨å·¥å…·"""
        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')

        if not (is_python or is_js):
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯.pyæˆ–.jsæ–‡ä»¶")

        command = "python" if is_python else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=None
        )

        # å¯åŠ¨MCPæœåŠ¡å™¨å¹¶å»ºç«‹é€šä¿¡
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
        self.stdio, self.write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))
        await self.session.initialize()

        # åˆ—å‡ºMCPæœåŠ¡å™¨ä¸Šçš„å·¥å…·
        response = await self.session.list_tools()
        tools = response.tools
        print("\nå·²è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ”¯æŒä»¥ä¸‹å·¥å…·:", [tool.name for tool in tools])

    async def process_query(self, query: str) -> str:
        """
        ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†æŸ¥è¯¢å¹¶è°ƒç”¨å¯ç”¨çš„MCPå·¥å…· (Function Calling)
        """
        messages = [{"role": "user", "content": query}]

        response = await self.session.list_tools()

        available_tools = [{
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.inputSchema
            }
        } for tool in response.tools]
        # print(available_tools)

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            tools=available_tools
        )

        # å¤„ç†è¿”å›çš„å†…å®¹
        content = response.choices[0]
        if content.finish_reason == "tool_calls":
            # å¦‚æœæ˜¯éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå°±è§£æå·¥å…·
            tool_call = content.message.tool_calls[0]
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)

            # æ‰§è¡Œå·¥å…·
            result = await self.session.call_tool(tool_name, tool_args)
            print(f"\n\n[Calling tool {tool_name} with args {tool_args}]\n\n")

            # å°†æ¨¡å‹è¿”å›çš„è°ƒç”¨å“ªä¸ªå·¥å…·æ•°æ®å’Œå·¥å…·æ‰§è¡Œå®Œæˆåçš„æ•°æ®éƒ½å­˜å…¥messagesä¸­
            messages.append(content.message.model_dump())
            messages.append({
                "role": "tool",
                "content": result.content[0].text,
                "tool_call_id": tool_call.id,
            })

            # å°†ä¸Šé¢çš„ç»“æœå†è¿”å›ç»™å¤§æ¨¡å‹ç”¨äºç”Ÿæˆæœ€ç»ˆçš„ç»“æœ
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
            )
            return response.choices[0].message.content

        return content.message.content

    async def chat_loop(self):
        """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"""
        print("\nğŸ¤– MCPå®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥'quit'é€€å‡º")
        while True:
            try:
                query = input("\nä½ : ").strip()
                if query.lower() == 'quit':
                    break

                response = await self.process_query(query)  # å‘é€ç”¨æˆ·è¾“å…¥åˆ°OpenAI API
                print(f"\nğŸ¤– OpenAI: {response}")
            except Exception as e:
                print(f"\nâš å‘ç”Ÿé”™è¯¯: {str(e)}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.exit_stack.aclose()


async def main():
    if len(sys.argv) < 2:
        print("Usage: python client.py <path_to_server_script>")
        sys.exit(1)
    client = MCPClient()
    try:
        await client.connect_to_server(sys.argv[1])
        await client.chat_loop()
    finally:
        await client.cleanup()


if __name__ == "__main__":
    import sys
    asyncio.run(main())
```

### 2.5 è¿è¡Œ

```bash
uv run 01_client.py 01_server.py
```

![](images/2025-03-21_172647.png)



**å‚è€ƒï¼š**

OpenWeatherå®˜ç½‘ï¼š https://openweathermap.org/